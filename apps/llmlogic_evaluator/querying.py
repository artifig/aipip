# Logic for querying LLMs with problems
# Adapted from https://github.com/tammet/llmlog/blob/main/askllm.py by Tanel Tammet
# Original License: Apache-2.0

import json
import time # Potentially needed if we add rate limiting/retries
from typing import List, Dict, Any

# Import from aipip (assuming it's installed)
from aipip.services.text_generation_service import TextGenerationService

# ================== Prompt Formatting ==================

# makeprompt_v1 from askllm.py
def format_prompt_v1(problem_data: Dict[str, Any]) -> str:
    """Formats a logic problem into a natural language prompt (v1 style)."""
    # problem_data is expected to be a dict like the one generated by generation.py
    # It should contain the key "problem_clauses"
    if "problem_clauses" not in problem_data:
        raise ValueError("Problem data missing 'problem_clauses' key.")
    clauses = problem_data["problem_clauses"]

    prefix = "Your task is to solve a problem in propositional logic.\n"
    prefix += "You will get a list of statements and have to determine whether the statements form a logical contradiction or not.\n"
    prefix += "If the statements form a contradiction, the last word of your answer should be 'contradiction',\n"
    prefix += "otherwise the last word should be either 'satisfiable' or 'unknown'.\n\n"

    details = "Propositional variables are represent as 'pN' where N is a number. They are either true or false.\n"
    details += "'X or Y' means that X is true or Y is true or both X and Y are true.\n"
    details += "All the given statements are implicitly connected with 'and': they are all claimed to be true.\n\n"

    example = "Two examples:\n"
    example += "Example 1. Statements: p1 is true. p1 is false or p2 is true. p2 is false. Answer: contradiction.\n"
    example += "Example 2. Statements: p1 is true. p1 is true or p2 is true. p2 is false. Answer: satisfiable.\n\n"

    statements = "Statements:\n"
    for clause in clauses:
        statement = ""
        for var in clause:
            if var > 0:
                s = "p" + str(var) + " is true"
            else:
                s = "p" + str(0 - var) + " is false"
            if statement:
                statement += " or " + s
            else:
                statement = s
        statement = statement + ".\n"
        statements += statement

    final = "\nPlease think step by step and answer whether the given statements form a logical contradiction or is satisfiable.\n"

    prompt = prefix + details + example + statements + final
    return prompt

# ================== Response Parsing ==================

# parse_result from askllm.py
def parse_llm_response(response_text: str) -> int:
    """Parses the LLM text response to extract a claim.

    Returns:
        0: If response indicates UNSAT/contradiction.
        1: If response indicates SAT/satisfiable.
        2: If response is unknown or unclear.
    """
    if not response_text:
        return 2 # Unknown if empty

    # Normalize: Lowercase, remove punctuation, split into words
    processed_text = response_text.replace(".", "").replace(",", " ").replace(":", " ")
    processed_text = processed_text.replace("*", "").replace("'", "").replace("\n", " ").replace("\r", " ")
    processed_text = processed_text.strip().lower()
    words = processed_text.split()

    if not words:
        return 2 # Unknown if only whitespace/punctuation

    last_word = words[-1]

    if last_word in ["contradiction", "contradictory", "false", "wrong", "unsatisfiable"]:
        return 0 # UNSAT
    elif last_word in ["satisfiable", "true", "satisfied", "sat"]:
        return 1 # SAT
    elif last_word in ["unknown", "uncertain"]:
        # Treat uncertain as SAT based on original script logic?
        # Let's keep it as unknown for clarity for now.
        # return 1
        return 2 # UNKNOWN
    else:
        # Check if keywords appear elsewhere (more robust but might misinterpret)
        # Swap order: Check for SAT first, then UNSAT/Contradiction
        if "satisfiable" in processed_text:
            return 1
        if "unsatisfiable" in processed_text or "contradiction" in processed_text:
            return 0
        # If none of the keywords are found clearly
        return 2 # UNKNOWN

# ================== Main Querying Function ==================

def run_querying(input_file: str, output_file: str, service: TextGenerationService, model_provider_list: List[tuple[str, str]], **kwargs):
    """Runs queries for problems in a dataset against specified LLMs.

    Reads problems from input_file, queries models via the TextGenerationService,
    parses the responses, and appends results to output_file.

    Args:
        input_file: Path to the input problems file (JSON Lines).
        output_file: Path to the output results file (JSON Lines).
        service: An initialized TextGenerationService instance.
        model_provider_list: List of (provider_name, model_name) tuples to query.
        **kwargs: Additional generation parameters (temperature, max_tokens, etc.).
                 Should be compatible with aipip service's generate method.
    """
    print(f"Starting LLM querying...")
    print(f"  Input problems: {input_file}")
    print(f"  Output results: {output_file}")
    # Combine model/provider info for printing
    models_str = ", ".join([f"{p}:{m}" for p, m in model_provider_list])
    print(f"  Models (Provider:Model): {models_str}")
    print(f"  Generation Params: {kwargs}")

    # Prepare generation parameters (filter out None values if needed by service)
    generation_params = {k: v for k, v in kwargs.items() if v is not None}

    problems_processed = 0
    results_written = 0
    errors_encountered = 0

    try:
        with open(input_file, 'r') as infile, open(output_file, 'a') as outfile:
            for line in infile:
                try:
                    problem_data = json.loads(line.strip())
                except json.JSONDecodeError:
                    print(f"Warning: Skipping invalid JSON line in {input_file}: {line.strip()}")
                    continue

                problems_processed += 1
                print(f"\nProcessing problem ID: {problem_data.get('id', 'N/A')}")

                # Format the prompt for this problem
                try:
                    prompt = format_prompt_v1(problem_data)
                except ValueError as e:
                    print(f"Error formatting prompt for problem {problem_data.get('id', 'N/A')}: {e}. Skipping.")
                    errors_encountered += 1
                    continue

                # Query each specified model for this problem
                for provider_name, model_name in model_provider_list:
                    print(f"  Querying model: {model_name} (Provider: {provider_name})...")
                    try:
                        # Call the aipip service, now passing provider_name
                        response_data = service.generate(
                            provider_name=provider_name,
                            model=model_name,
                            prompt=prompt,
                            **generation_params
                        )
                        response_text = response_data.text
                        # We already have provider_name, but confirm if service returns it too
                        returned_provider = response_data.provider_name
                        print(f"    Provider: {returned_provider}, Response received ({len(response_text)} chars). Parsing...")

                    except Exception as e:
                        print(f"Error calling TextGenerationService for model {model_name} (provider {provider_name}) on problem {problem_data.get('id', 'N/A')}: {e}")
                        response_text = f"ERROR: {e}"
                        # Use the intended provider_name even if call failed
                        returned_provider = provider_name
                        errors_encountered += 1

                    # Parse the LLM response
                    parsed_claim = parse_llm_response(response_text)
                    print(f"    Parsed claim: {parsed_claim} (0=UNSAT, 1=SAT, 2=Unknown)")

                    # Structure the result
                    result_data = {
                        "problem": problem_data,
                        "query_info": {
                            "model": model_name,
                            "provider": returned_provider, # Use provider name from service/input
                            "prompt": prompt,
                            "generation_params": generation_params,
                        },
                        "llm_response": {
                            "text": response_text,
                            "parsed_claim": parsed_claim,
                        }
                    }

                    # Write result to output file
                    try:
                        json.dump(result_data, outfile)
                        outfile.write('\n')
                        results_written += 1
                    except IOError as e:
                        print(f"Error writing result to {output_file}: {e}")
                        errors_encountered += 1

    except FileNotFoundError:
        print(f"Error: Input file not found: {input_file}")
        return # Stop if input file is missing
    except IOError as e:
        print(f"Error opening input/output file: {e}")
        return # Stop on other file errors

    print("\nQuerying complete.")
    print(f"  Problems processed: {problems_processed}")
    print(f"  Model queries performed (results written): {results_written}")
    print(f"  Errors encountered: {errors_encountered}") 